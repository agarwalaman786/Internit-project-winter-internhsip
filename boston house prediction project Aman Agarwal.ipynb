{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split #just to check the accuracy\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_x=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "df_y=pd.DataFrame(boston.target)\n",
    "df_x.info()##All entries contains some values it means our data is fresh and does not contain any of the NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=lm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error=y_test-y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554467329645208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pre)   ###Starting R**2 value is 0.75 now we have the p values by stastsmodel and we will remove the variables those have high p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared:         </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.725</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   82.65</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>2.45e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:14:40</td>     <th>  Log-Likelihood:    </th> <td> -1194.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2417.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2473.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.3480</td> <td>    5.724</td> <td>    6.350</td> <td> 0.000</td> <td>   25.094</td> <td>   47.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.0802</td> <td>    0.043</td> <td>   -1.854</td> <td> 0.065</td> <td>   -0.165</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0480</td> <td>    0.015</td> <td>    3.123</td> <td> 0.002</td> <td>    0.018</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>   -0.0051</td> <td>    0.070</td> <td>   -0.072</td> <td> 0.943</td> <td>   -0.144</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.0649</td> <td>    0.915</td> <td>    3.348</td> <td> 0.001</td> <td>    1.265</td> <td>    4.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -16.1597</td> <td>    4.263</td> <td>   -3.791</td> <td> 0.000</td> <td>  -24.541</td> <td>   -7.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.6686</td> <td>    0.473</td> <td>    7.753</td> <td> 0.000</td> <td>    2.738</td> <td>    4.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>   -0.0085</td> <td>    0.015</td> <td>   -0.570</td> <td> 0.569</td> <td>   -0.038</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.5172</td> <td>    0.228</td> <td>   -6.658</td> <td> 0.000</td> <td>   -1.965</td> <td>   -1.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2866</td> <td>    0.074</td> <td>    3.882</td> <td> 0.000</td> <td>    0.141</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0121</td> <td>    0.004</td> <td>   -2.891</td> <td> 0.004</td> <td>   -0.020</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9248</td> <td>    0.148</td> <td>   -6.244</td> <td> 0.000</td> <td>   -1.216</td> <td>   -0.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0096</td> <td>    0.003</td> <td>    3.040</td> <td> 0.003</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.4867</td> <td>    0.057</td> <td>   -8.541</td> <td> 0.000</td> <td>   -0.599</td> <td>   -0.375</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>134.965</td> <th>  Durbin-Watson:     </th> <td>   2.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 516.862</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.452</td>  <th>  Prob(JB):          </th> <td>5.82e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.719</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      0   R-squared:                       0.734\n",
       "Model:                            OLS   Adj. R-squared:                  0.725\n",
       "Method:                 Least Squares   F-statistic:                     82.65\n",
       "Date:                Thu, 07 Feb 2019   Prob (F-statistic):          2.45e-103\n",
       "Time:                        16:14:40   Log-Likelihood:                -1194.4\n",
       "No. Observations:                 404   AIC:                             2417.\n",
       "Df Residuals:                     390   BIC:                             2473.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.3480      5.724      6.350      0.000      25.094      47.602\n",
       "CRIM          -0.0802      0.043     -1.854      0.065      -0.165       0.005\n",
       "ZN             0.0480      0.015      3.123      0.002       0.018       0.078\n",
       "INDUS         -0.0051      0.070     -0.072      0.943      -0.144       0.134\n",
       "CHAS           3.0649      0.915      3.348      0.001       1.265       4.865\n",
       "NOX          -16.1597      4.263     -3.791      0.000     -24.541      -7.778\n",
       "RM             3.6686      0.473      7.753      0.000       2.738       4.599\n",
       "AGE           -0.0085      0.015     -0.570      0.569      -0.038       0.021\n",
       "DIS           -1.5172      0.228     -6.658      0.000      -1.965      -1.069\n",
       "RAD            0.2866      0.074      3.882      0.000       0.141       0.432\n",
       "TAX           -0.0121      0.004     -2.891      0.004      -0.020      -0.004\n",
       "PTRATIO       -0.9248      0.148     -6.244      0.000      -1.216      -0.634\n",
       "B              0.0096      0.003      3.040      0.003       0.003       0.016\n",
       "LSTAT         -0.4867      0.057     -8.541      0.000      -0.599      -0.375\n",
       "==============================================================================\n",
       "Omnibus:                      134.965   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              516.862\n",
       "Skew:                           1.452   Prob(JB):                    5.82e-113\n",
       "Kurtosis:                       7.719   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sma\n",
    "X_train = sma.add_constant(x_train)## let's add an intercept (beta_0) to our model\n",
    "X_test = sma.add_constant(x_test)\n",
    "import statsmodels.formula.api as sm\n",
    "lm2 = sm.OLS(y_train,X_train).fit()\n",
    "lm2.summary()   ##first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['INDUS'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b790595217d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INDUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['INDUS'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_x=df_x.drop(['INDUS'],axis=1)  #I have already removed INDUS thats why it is giving me error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=linear_model.LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lm1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error=y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556021345562353"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)   ###Now R2 value is increased in some points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared:         </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   89.77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>2.54e-104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:47:51</td>     <th>  Log-Likelihood:    </th> <td> -1194.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2415.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   2467.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.3740</td> <td>    5.706</td> <td>    6.375</td> <td> 0.000</td> <td>   25.156</td> <td>   47.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.0799</td> <td>    0.043</td> <td>   -1.856</td> <td> 0.064</td> <td>   -0.165</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0481</td> <td>    0.015</td> <td>    3.152</td> <td> 0.002</td> <td>    0.018</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.0577</td> <td>    0.909</td> <td>    3.364</td> <td> 0.001</td> <td>    1.271</td> <td>    4.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -16.2334</td> <td>    4.133</td> <td>   -3.928</td> <td> 0.000</td> <td>  -24.359</td> <td>   -8.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.6712</td> <td>    0.471</td> <td>    7.792</td> <td> 0.000</td> <td>    2.745</td> <td>    4.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>   -0.0084</td> <td>    0.015</td> <td>   -0.569</td> <td> 0.570</td> <td>   -0.038</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.5135</td> <td>    0.222</td> <td>   -6.825</td> <td> 0.000</td> <td>   -1.950</td> <td>   -1.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2882</td> <td>    0.070</td> <td>    4.094</td> <td> 0.000</td> <td>    0.150</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.337</td> <td> 0.001</td> <td>   -0.019</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9262</td> <td>    0.147</td> <td>   -6.321</td> <td> 0.000</td> <td>   -1.214</td> <td>   -0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0096</td> <td>    0.003</td> <td>    3.048</td> <td> 0.002</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.4872</td> <td>    0.056</td> <td>   -8.628</td> <td> 0.000</td> <td>   -0.598</td> <td>   -0.376</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>134.925</td> <th>  Durbin-Watson:     </th> <td>   2.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 516.375</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.452</td>  <th>  Prob(JB):          </th> <td>7.42e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.716</td>  <th>  Cond. No.          </th> <td>1.50e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.5e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      0   R-squared:                       0.734\n",
       "Model:                            OLS   Adj. R-squared:                  0.726\n",
       "Method:                 Least Squares   F-statistic:                     89.77\n",
       "Date:                Thu, 07 Feb 2019   Prob (F-statistic):          2.54e-104\n",
       "Time:                        18:47:51   Log-Likelihood:                -1194.4\n",
       "No. Observations:                 404   AIC:                             2415.\n",
       "Df Residuals:                     391   BIC:                             2467.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.3740      5.706      6.375      0.000      25.156      47.592\n",
       "CRIM          -0.0799      0.043     -1.856      0.064      -0.165       0.005\n",
       "ZN             0.0481      0.015      3.152      0.002       0.018       0.078\n",
       "CHAS           3.0577      0.909      3.364      0.001       1.271       4.845\n",
       "NOX          -16.2334      4.133     -3.928      0.000     -24.359      -8.108\n",
       "RM             3.6712      0.471      7.792      0.000       2.745       4.597\n",
       "AGE           -0.0084      0.015     -0.569      0.570      -0.038       0.021\n",
       "DIS           -1.5135      0.222     -6.825      0.000      -1.950      -1.077\n",
       "RAD            0.2882      0.070      4.094      0.000       0.150       0.427\n",
       "TAX           -0.0123      0.004     -3.337      0.001      -0.019      -0.005\n",
       "PTRATIO       -0.9262      0.147     -6.321      0.000      -1.214      -0.638\n",
       "B              0.0096      0.003      3.048      0.002       0.003       0.016\n",
       "LSTAT         -0.4872      0.056     -8.628      0.000      -0.598      -0.376\n",
       "==============================================================================\n",
       "Omnibus:                      134.925   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              516.375\n",
       "Skew:                           1.452   Prob(JB):                    7.42e-113\n",
       "Kurtosis:                       7.716   Cond. No.                     1.50e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.5e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Now we check the p values\n",
    "import statsmodels.api as sma\n",
    "X_train = sma.add_constant(x_train)## let's add an intercept (beta_0) to our model\n",
    "X_test = sma.add_constant(x_test)\n",
    "import statsmodels.formula.api as sm\n",
    "lm2 = sm.OLS(y_train,X_train).fit()\n",
    "lm2.summary()   ##second observation ##Now p value of age is greater than the 0.05 than we will remove tha age from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.drop(['AGE'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B',\n",
       "       'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=100)\n",
    "lm3=linear_model.LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prede=lm3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574083614000353"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_prede)  #now it is incresed in some ratio that is our 3rd observation our accuracy is 75.74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared:         </th> <td>   0.733</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   98.07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>2.94e-105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:54:53</td>     <th>  Log-Likelihood:    </th> <td> -1194.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2413.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   392</td>      <th>  BIC:               </th> <td>   2461.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.6195</td> <td>    5.684</td> <td>    6.442</td> <td> 0.000</td> <td>   25.444</td> <td>   47.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.0800</td> <td>    0.043</td> <td>   -1.859</td> <td> 0.064</td> <td>   -0.165</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0493</td> <td>    0.015</td> <td>    3.260</td> <td> 0.001</td> <td>    0.020</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.0395</td> <td>    0.908</td> <td>    3.349</td> <td> 0.001</td> <td>    1.255</td> <td>    4.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -16.8743</td> <td>    3.973</td> <td>   -4.247</td> <td> 0.000</td> <td>  -24.685</td> <td>   -9.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.6171</td> <td>    0.461</td> <td>    7.845</td> <td> 0.000</td> <td>    2.711</td> <td>    4.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4734</td> <td>    0.210</td> <td>   -7.013</td> <td> 0.000</td> <td>   -1.887</td> <td>   -1.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2909</td> <td>    0.070</td> <td>    4.145</td> <td> 0.000</td> <td>    0.153</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.346</td> <td> 0.001</td> <td>   -0.019</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9328</td> <td>    0.146</td> <td>   -6.391</td> <td> 0.000</td> <td>   -1.220</td> <td>   -0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0095</td> <td>    0.003</td> <td>    3.016</td> <td> 0.003</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.4982</td> <td>    0.053</td> <td>   -9.396</td> <td> 0.000</td> <td>   -0.602</td> <td>   -0.394</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>132.865</td> <th>  Durbin-Watson:     </th> <td>   2.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 497.795</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.436</td>  <th>  Prob(JB):          </th> <td>8.04e-109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.618</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      0   R-squared:                       0.733\n",
       "Model:                            OLS   Adj. R-squared:                  0.726\n",
       "Method:                 Least Squares   F-statistic:                     98.07\n",
       "Date:                Thu, 07 Feb 2019   Prob (F-statistic):          2.94e-105\n",
       "Time:                        18:54:53   Log-Likelihood:                -1194.6\n",
       "No. Observations:                 404   AIC:                             2413.\n",
       "Df Residuals:                     392   BIC:                             2461.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.6195      5.684      6.442      0.000      25.444      47.795\n",
       "CRIM          -0.0800      0.043     -1.859      0.064      -0.165       0.005\n",
       "ZN             0.0493      0.015      3.260      0.001       0.020       0.079\n",
       "CHAS           3.0395      0.908      3.349      0.001       1.255       4.824\n",
       "NOX          -16.8743      3.973     -4.247      0.000     -24.685      -9.063\n",
       "RM             3.6171      0.461      7.845      0.000       2.711       4.524\n",
       "DIS           -1.4734      0.210     -7.013      0.000      -1.887      -1.060\n",
       "RAD            0.2909      0.070      4.145      0.000       0.153       0.429\n",
       "TAX           -0.0123      0.004     -3.346      0.001      -0.019      -0.005\n",
       "PTRATIO       -0.9328      0.146     -6.391      0.000      -1.220      -0.646\n",
       "B              0.0095      0.003      3.016      0.003       0.003       0.016\n",
       "LSTAT         -0.4982      0.053     -9.396      0.000      -0.602      -0.394\n",
       "==============================================================================\n",
       "Omnibus:                      132.865   Durbin-Watson:                   2.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              497.795\n",
       "Skew:                           1.436   Prob(JB):                    8.04e-109\n",
       "Kurtosis:                       7.618   Cond. No.                     1.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Now we check the p values\n",
    "import statsmodels.api as sma\n",
    "X_train = sma.add_constant(x_train)## let's add an intercept (beta_0) to our model\n",
    "X_test = sma.add_constant(x_test)\n",
    "import statsmodels.formula.api as sm\n",
    "lm2 = sm.OLS(y_train,X_train).fit()\n",
    "lm2.summary()   ##3rd observation ##Now p value of age is greater than the 0.05 than we will remove tha age from our dataset\n",
    "\n",
    "##Lets remove the one more variable CRIM beacuse its value is also greater than the 0.05 but it is very closed to it thats why we will not remove it it will affect our accuracy if you want to see than we can see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B',\n",
       "       'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now I have removed the variable CRIM\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=100)\n",
    "lm4=linear_model.LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prede=lm4.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426511158955971"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_prede)  ##Now our accuarcy is nearly 74.2% this is our 4th observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared:         </th> <td>   0.731</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.724</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   106.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>1.52e-105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:08:40</td>     <th>  Log-Likelihood:    </th> <td> -1196.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2415.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   393</td>      <th>  BIC:               </th> <td>   2459.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   35.6064</td> <td>    5.676</td> <td>    6.273</td> <td> 0.000</td> <td>   24.448</td> <td>   46.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0459</td> <td>    0.015</td> <td>    3.051</td> <td> 0.002</td> <td>    0.016</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    3.1342</td> <td>    0.909</td> <td>    3.448</td> <td> 0.001</td> <td>    1.347</td> <td>    4.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -16.2163</td> <td>    3.969</td> <td>   -4.085</td> <td> 0.000</td> <td>  -24.020</td> <td>   -8.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.6683</td> <td>    0.462</td> <td>    7.946</td> <td> 0.000</td> <td>    2.761</td> <td>    4.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4230</td> <td>    0.209</td> <td>   -6.809</td> <td> 0.000</td> <td>   -1.834</td> <td>   -1.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2467</td> <td>    0.066</td> <td>    3.724</td> <td> 0.000</td> <td>    0.116</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0119</td> <td>    0.004</td> <td>   -3.240</td> <td> 0.001</td> <td>   -0.019</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9217</td> <td>    0.146</td> <td>   -6.301</td> <td> 0.000</td> <td>   -1.209</td> <td>   -0.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0102</td> <td>    0.003</td> <td>    3.240</td> <td> 0.001</td> <td>    0.004</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.5198</td> <td>    0.052</td> <td>  -10.019</td> <td> 0.000</td> <td>   -0.622</td> <td>   -0.418</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>128.300</td> <th>  Durbin-Watson:     </th> <td>   2.072</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 476.608</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.385</td>  <th>  Prob(JB):          </th> <td>3.21e-104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.543</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      0   R-squared:                       0.731\n",
       "Model:                            OLS   Adj. R-squared:                  0.724\n",
       "Method:                 Least Squares   F-statistic:                     106.9\n",
       "Date:                Thu, 07 Feb 2019   Prob (F-statistic):          1.52e-105\n",
       "Time:                        19:08:40   Log-Likelihood:                -1196.4\n",
       "No. Observations:                 404   AIC:                             2415.\n",
       "Df Residuals:                     393   BIC:                             2459.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         35.6064      5.676      6.273      0.000      24.448      46.765\n",
       "ZN             0.0459      0.015      3.051      0.002       0.016       0.076\n",
       "CHAS           3.1342      0.909      3.448      0.001       1.347       4.921\n",
       "NOX          -16.2163      3.969     -4.085      0.000     -24.020      -8.412\n",
       "RM             3.6683      0.462      7.946      0.000       2.761       4.576\n",
       "DIS           -1.4230      0.209     -6.809      0.000      -1.834      -1.012\n",
       "RAD            0.2467      0.066      3.724      0.000       0.116       0.377\n",
       "TAX           -0.0119      0.004     -3.240      0.001      -0.019      -0.005\n",
       "PTRATIO       -0.9217      0.146     -6.301      0.000      -1.209      -0.634\n",
       "B              0.0102      0.003      3.240      0.001       0.004       0.016\n",
       "LSTAT         -0.5198      0.052    -10.019      0.000      -0.622      -0.418\n",
       "==============================================================================\n",
       "Omnibus:                      128.300   Durbin-Watson:                   2.072\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              476.608\n",
       "Skew:                           1.385   Prob(JB):                    3.21e-104\n",
       "Kurtosis:                       7.543   Cond. No.                     1.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Now we check the p values\n",
    "import statsmodels.api as sma\n",
    "X_train = sma.add_constant(x_train)## let's add an intercept (beta_0) to our model\n",
    "X_test = sma.add_constant(x_test)\n",
    "import statsmodels.formula.api as sm\n",
    "lm2 = sm.OLS(y_train,X_train).fit()\n",
    "lm2.summary()  #Now we don't have any variable whose p value is greater than the 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict R^2 value according to our observations\n",
    "#1. 0.7554467329645208\n",
    "#2. 0.7556021345562353\n",
    "#3. 0.7574083614000353\n",
    "#4. 0.7426511158955971               #this is our predicted r-square values according to our results in which 3rd one is much good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
